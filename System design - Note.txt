

所以，簡單小結，第一步要做的：

1.添加負載均衡層，將請求均勻打到系統層。
2.系統層採用集羣化部署多臺機器，扛住初步的併發壓力。

load balance



高併發可以通過分散式技術去解決，將併發流量分不到不同的物理伺服器上。但除此之外，還可以有很多其他優化手段：比如使用快取系統，將所有的，靜態內容放到CDN等;還可以使用多執行緒技術將一臺伺服器的服務能力最大化。



1.分散式快取：redis、memcached等，結合CDN來解決圖片檔案等訪問。

2.訊息佇列中介軟體：activeMQ等，解決大量訊息的非同步處理能力。

3.應用拆分:一個工程被拆分為多個工程部署，利用dubbo解決多工程之間的通訊。

4.資料庫垂直拆分和水平拆分(分庫分表)等。

5.資料庫讀寫分離，解決大資料的查詢問題。

6.還可以利用nosql ，例如mongoDB配合mysql組合使用。

7.還需要建立大資料訪問情況下的服務降級以及限流機制等。

 



System design - note

Q: a web service massively scalable --> 
A: lengthy 1. Clones 2. Database 3. Cache 4. Asynchronism

1. Clones
Load Balancer
That leads to the first golden rule for scalability: 
every server contains exactly the same codebase and does not store any user-related data, like sessions or profile pictures, on local disc or memory. 

Sessions need to be stored in a centralized data store which is accessible to all your application servers. 
Such as an external database or an external persistent cache, like Redis.

Using load balancer could horizontally scale and you can already serve thousands of concurrent requests.


2. Database

I. Using master-slave replication (read from slaves, write to master)
and upgrade your master server by adding RAM

II. (Better) means to denormalize right from the beginning and include no more Joins in any database query.
switch to a better and easier to scale NoSQL database like MongoDB or CouchDB.
Joins will now need to be done in your application code.

But even if you successfully switch to the latest and greatest NoSQL database and 
let your app do the dataset-joins, soon your database requests will again be slower and slower. 
You will need to introduce a cache.


3. Cache

Q: Your users still have to suffer slow page requests when a lot of data is fetched from the database.
A: cache. like Memcached or Redis

Implementation: 

I. Cached Database Queries
you store the result dataset in cache. A hashed version of your query is the cache key.

II. Cached Objects

Now, do the following: when your class has finished the “assembling” of the data array, 
directly store the data array in the cache!

Some ideas of objects to cache:

i. user sessions (never use the database!)
ii. fully rendered blog articles


4. Asynchronism

I. Referring to a web app this means doing the time-consuming work in advance and 
serving the finished work with a low request time.

Just imagine the scalability of your website if the script would upload these pre-rendered HTML 
pages to AWS S3 or Cloudfront or another Content Delivery Network! 
Your website would be super responsive and could handle millions of visitors per hour!

II. could not preload 
--> RabbitMQ is one of many systems which help to implement async processing.


PS: If you do something time-consuming, try to do it always asynchronously. 





System design - note

Q: a web service massively scalable --> 
A: lengthy 1. Clones 2. Database 3. Cache 4. Asynchronism

1. Clones
Load Balancer
That leads to the first golden rule for scalability: 
every server contains exactly the same codebase and does not store any user-related data, like sessions or profile pictures, on local disc or memory. 

Sessions need to be stored in a centralized data store which is accessible to all your application servers. 
Such as an external database or an external persistent cache, like Redis.

Using load balancer could horizontally scale and you can already serve thousands of concurrent requests.


2. Database

I. Using master-slave replication (read from slaves, write to master)
and upgrade your master server by adding RAM

II. (Better) means to denormalize right from the beginning and include no more Joins in any database query.
switch to a better and easier to scale NoSQL database like MongoDB or CouchDB.
Joins will now need to be done in your application code.

But even if you successfully switch to the latest and greatest NoSQL database and 
let your app do the dataset-joins, soon your database requests will again be slower and slower. 
You will need to introduce a cache.


3. Cache

Q: Your users still have to suffer slow page requests when a lot of data is fetched from the database.
A: cache. like Memcached or Redis

Implementation: 

I. Cached Database Queries
you store the result dataset in cache. A hashed version of your query is the cache key.

II. Cached Objects

Now, do the following: when your class has finished the “assembling” of the data array, 
directly store the data array in the cache!

Some ideas of objects to cache:

i. user sessions (never use the database!)
ii. fully rendered blog articles


4. Asynchronism

I. Referring to a web app this means doing the time-consuming work in advance and 
serving the finished work with a low request time.

Just imagine the scalability of your website if the script would upload these pre-rendered HTML 
pages to AWS S3 or Cloudfront or another Content Delivery Network! 
Your website would be super responsive and could handle millions of visitors per hour!

II. could not preload 
--> RabbitMQ is one of many systems which help to implement async processing.


PS: If you do something time-consuming, try to do it always asynchronously. 



****** A Plain English Introduction to CAP Theorem *****

CAP Theorem:
You can pick only two of:

1. Consistency: You customers, once they have updated information with you, will always get the most updated information when they call subsequently. No matter how quickly they call back
2. Availability: Remembrance Inc will always be available for calls until any one of you(you or your wife) report to work.
3. Partition Tolerance: Remembrance Inc will work even if there is a communication loss between you and your wife!


1. Availability - will a request made to the data store always eventually complete?
2. Consistency - will all executions of reads and writes seen by all nodes be atomic or linearizably consistent?
3. Partition tolerance - the network is allowed to drop any messages.

What is a partition?

The term is sometimes used to refer to a period during which no messages are delivered between two sets of nodes.




***********  Introduction to architecting systems for scale. ****************

Cache invalidation

You can consider relying fully on database caching, adding aggressive expirations to the cached data, or reworking your application's logic to avoid the issue (e.g. instead of DELETE FROM a WHERE..., retrieve all the items which match the criteria, invalidate the corresponding cache rows and then delete the rows by their primary key explicitly).


Platform layer

1. separating the platform and web application allow you to scale the pieces independently.
2. a sometimes underappreciated aspect of platform layers is that they make it easier to scale an organization.

EX: you have a web site that serves some pages and does some very heavy calculations for some requests.

If both of these functions were on the web server, then a calculation could slow the response time of the web pages. Having it on a seperate server avoids this problem.

In our architecture drawings we call this layer the application server or business layer rather than the platform layer. We call Azure or the .net framework a platform.







***************** Transactions Across Datacenters  *****************

multihoming --> is the practice of connecting a host or a computer network to more than one network. This can be done in order to increase reliability or performance.


